{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNB Classifier (courtesy of ML hw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNB_TextClassifier:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.prior = {}\n",
    "        self.condprob = {}\n",
    "    \n",
    "    # p(class=y | {term0=x[0], term1=x[1], ...} )\n",
    "    # please note that you dont add new data to vocabulary when predicting\n",
    "    def proba_y_given_x(self, y, x):\n",
    "        length = len(self.condprob)\n",
    "        prob_y = self.prior[y]\n",
    "        prob_x = 1\n",
    "        for i in x:\n",
    "            if(i in self.condprob.keys()):\n",
    "                prob_x *= (self.condprob[i][y])\n",
    "            else:\n",
    "                prob_x *= ((1)/(self.dict_y_term[y] + length))\n",
    "        return prob_y * prob_x\n",
    " \n",
    "        #raise NotImplementedError()\n",
    "    \n",
    "    # p(c)\n",
    "    def proba_y(self, y):\n",
    "        return self.prior[y]\n",
    "\n",
    "    # update self.prior[class] as p(class=class) \n",
    "    # update self.condprob[term][class] as p(term=term | class=class)\n",
    "    def fit(self, X, y):\n",
    "        dict_y = {i:list(y).count(i) for i in y}\n",
    "        total_y = 0\n",
    "\n",
    "        for i in dict_y:\n",
    "            total_y += dict_y[i]\n",
    "        for i in dict_y:\n",
    "            self.prior[i] = dict_y[i]/total_y\n",
    "        \n",
    "        X_Plain = list()\n",
    "        \n",
    "        for i in X:\n",
    "            for j in i:\n",
    "                X_Plain.append(j)\n",
    "\n",
    "        dict_x = {i:X_Plain.count(i) for i in X_Plain}\n",
    "        dict_x_dict_y = {i:dict() for i in dict_x}\n",
    "        dict_x_cond_y = {i:dict() for i in dict_x}\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            for j in X[i]:\n",
    "                if(i in dict_x_cond_y[j]):\n",
    "                    dict_x_cond_y[j][i] += 1\n",
    "                else:\n",
    "                    dict_x_cond_y[j][i] = 1\n",
    "        self.dict_y_term = {i:0 for i in y}\n",
    "        for i in range(len(y)):\n",
    "            self.dict_y_term[y[i]] += (len(X[i]))\n",
    "\n",
    "        dict_y_last = {i:{j:0 for j in self.dict_y_term} for i in dict_x_cond_y}\n",
    "\n",
    "        for i in dict_x_cond_y:\n",
    "            for j in range(len(y)):\n",
    "                if(j in dict_x_cond_y[i]):\n",
    "                    dict_y_last[i][y[j]] += dict_x_cond_y[i][j] \n",
    "        self.condprob = {i:{j:0 for j in self.dict_y_term} for i in dict_x_cond_y}\n",
    "        for i in dict_y_last:\n",
    "            for j in dict_y_last[i]:\n",
    "\n",
    "                self.condprob[i][j] = (dict_y_last[i][j] + 1)/(self.dict_y_term[j] + len(dict_x))\n",
    "        #print(dict_x)\n",
    "        #print(self.dict_y_term)\n",
    "        #print(dict_y_last)\n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "    def predict_single(self, x):\n",
    "        classes = [i for i in self.prior.keys()]\n",
    "        likelihood = [self.proba_y_given_x(i,x) for i in classes]\n",
    "        return classes[likelihood.index(max(likelihood))]\n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return [self.predict_single(x) for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using single annotator csv as <b>TRAIN DATA</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kalimat_id</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>336691</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>cuaca cerah lazim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>336270</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>gambar dihasilkan layarnya cerah memiliki spea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>336555</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4803</td>\n",
       "      <td>cerah pemuda berumur 20 prancis abad 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>336618</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>cor caroli alpha canum venaticorum nama lengka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>336613</td>\n",
       "      <td>cerah</td>\n",
       "      <td>4801</td>\n",
       "      <td>sanders menyukai cat air lilo maksud menampilk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  kalimat_id   kata sense  \\\n",
       "0           0      336691  cerah  4801   \n",
       "1           1      336270  cerah  4801   \n",
       "2           2      336555  cerah  4803   \n",
       "3           3      336618  cerah  4801   \n",
       "4           4      336613  cerah  4801   \n",
       "\n",
       "                                             kalimat  \n",
       "0                                  cuaca cerah lazim  \n",
       "1  gambar dihasilkan layarnya cerah memiliki spea...  \n",
       "2            cerah pemuda berumur 20 prancis abad 17  \n",
       "3  cor caroli alpha canum venaticorum nama lengka...  \n",
       "4  sanders menyukai cat air lilo maksud menampilk...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_annotator = pd.read_csv(\"training_clean/clean_single_annotator.csv\",delimiter=\",\")\n",
    "single_annotator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004127130354675265"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is creating the MNB Text Classifier and fitting X to y\n",
    "\n",
    "df = single_annotator[single_annotator['kata']=='cerah']\n",
    "\n",
    "arr = [nltk.word_tokenize(df['kalimat'].iloc[i]) for i in range(len(df))]\n",
    "\n",
    "X = np.array(arr)\n",
    "\n",
    "y = np.array(df['sense'].values)\n",
    "\n",
    "clf = MNB_TextClassifier()\n",
    "clf.fit(X, y)\n",
    "clf.proba_y_given_x('4801',['cuaca']) #test proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using double annotator agree csv as <b>TEST DATA</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421052631578947"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_annotator_agree = pd.read_csv(\"training_clean/clean_double_annotator_agree.csv\",delimiter=\",\")\n",
    "\n",
    "df_test = double_annotator_agree[double_annotator_agree['kata']=='cerah']\n",
    "\n",
    "test_arr = [nltk.word_tokenize(df_test['kalimat'].iloc[i]) for i in range(len(df_test))]\n",
    "test_X = np.array(test_arr)\n",
    "\n",
    "test_y = np.array(df_test['sense'].values)\n",
    "\n",
    "y_pred = np.array(clf.predict(test_X))\n",
    "\n",
    "acc = sklearn.metrics.accuracy_score(test_y, \n",
    "                                     y_pred)\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['cuaca', 'cerah', 'lazim']),\n",
       "       list(['gambar', 'dihasilkan', 'layarnya', 'cerah', 'memiliki', 'speaker', 'menghasilkan', 'suara', 'keras', 'jernih']),\n",
       "       list(['cerah', 'pemuda', 'berumur', '20', 'prancis', 'abad', '17']),\n",
       "       list(['cor', 'caroli', 'alpha', 'canum', 'venaticorum', 'nama', 'lengkapnya', 'cor', 'caroli', 'regis', 'martyris', 'bintang', 'cerah', 'rasi', 'canes', 'venatici'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#single experiment, 4 samples\n",
    "\n",
    "a = nltk.word_tokenize(single_annotator['kalimat'][0])\n",
    "b = nltk.word_tokenize(single_annotator['kalimat'][1])\n",
    "c = nltk.word_tokenize(single_annotator['kalimat'][2])\n",
    "d = nltk.word_tokenize(single_annotator['kalimat'][3])\n",
    "\n",
    "X = np.array([\n",
    "    a,\n",
    "    b,\n",
    "    c,\n",
    "    d,\n",
    "])\n",
    "\n",
    "y = np.array([1,1,3,1])\n",
    "\n",
    "clf = MNB_TextClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.06666666666666667, 3: 0.05263157894736842}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.condprob['cerah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
