{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinomialNaive Bayes using SKLearn Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_single_annotator = pd.read_csv(\"training_clean/clean_single_annotator.csv\",delimiter=\",\")\n",
    "cleaned_double_annotator_agree = pd.read_csv(\"training_clean/clean_double_annotator_agree.csv\",delimiter=\",\")\n",
    "cleaned_double_annotator_disagree = pd.read_csv(\"training_clean/clean_double_annotator_disagree.csv\",delimiter=\",\")\n",
    "cleaned_triple_annotator_agree = pd.read_csv(\"training_clean/clean_triple_annotator_agree.csv\",delimiter=\",\")\n",
    "cleaned_triple_annotator_disagree = pd.read_csv(\"training_clean/clean_triple_annotator_disagree.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kalimat_id</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001238</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>berencana pulang amerika serikat volume 42 ber...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1001238</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>berencana pulang amerika serikat volume 42 ber...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1001448</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>mekanisme memicu produksi nasional ketidakpuas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1001448</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>mekanisme memicu produksi nasional ketidakpuas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1001820</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>ganti kaum melayu melepaskan ketuanan melayuny...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  kalimat_id      kata sense  \\\n",
       "0           0     1001238  mengejar  2801   \n",
       "1           1     1001238  mengejar  2802   \n",
       "2           2     1001448  mengejar  2801   \n",
       "3           3     1001448  mengejar  2802   \n",
       "4           4     1001820  mengejar  2801   \n",
       "\n",
       "                                             kalimat  freq  \n",
       "0  berencana pulang amerika serikat volume 42 ber...     1  \n",
       "1  berencana pulang amerika serikat volume 42 ber...     1  \n",
       "2  mekanisme memicu produksi nasional ketidakpuas...     1  \n",
       "3  mekanisme memicu produksi nasional ketidakpuas...     1  \n",
       "4  ganti kaum melayu melepaskan ketuanan melayuny...     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_double_annotator_disagree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns = requests.post('http://bahasa.cs.ui.ac.id/postag/API/tag',\n",
    "#                          data={'Text[value]':'gambar dihasilkan layarnya cerah memiliki speaker menghasilkan suara keras jernih'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_double_annotator_disagree['kalimat'] = cleaned_double_annotator_disagree['kalimat'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kalimat_id</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001238</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[berencana, pulang, amerika, serikat, volume, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1001238</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>[berencana, pulang, amerika, serikat, volume, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1001448</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[mekanisme, memicu, produksi, nasional, ketida...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1001448</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>[mekanisme, memicu, produksi, nasional, ketida...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1001820</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[ganti, kaum, melayu, melepaskan, ketuanan, me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  kalimat_id      kata sense  \\\n",
       "0           0     1001238  mengejar  2801   \n",
       "1           1     1001238  mengejar  2802   \n",
       "2           2     1001448  mengejar  2801   \n",
       "3           3     1001448  mengejar  2802   \n",
       "4           4     1001820  mengejar  2801   \n",
       "\n",
       "                                             kalimat  freq  \n",
       "0  [berencana, pulang, amerika, serikat, volume, ...     1  \n",
       "1  [berencana, pulang, amerika, serikat, volume, ...     1  \n",
       "2  [mekanisme, memicu, produksi, nasional, ketida...     1  \n",
       "3  [mekanisme, memicu, produksi, nasional, ketida...     1  \n",
       "4  [ganti, kaum, melayu, melepaskan, ketuanan, me...     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_double_annotator_disagree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kalimat_id</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001238</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[berencana, pulang, amerika, serikat, volume, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1001238</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>[berencana, pulang, amerika, serikat, volume, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1001448</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[mekanisme, memicu, produksi, nasional, ketida...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1001448</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>[mekanisme, memicu, produksi, nasional, ketida...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1001820</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[ganti, kaum, melayu, melepaskan, ketuanan, me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  kalimat_id      kata sense  \\\n",
       "0           0     1001238  mengejar  2801   \n",
       "1           1     1001238  mengejar  2802   \n",
       "2           2     1001448  mengejar  2801   \n",
       "3           3     1001448  mengejar  2802   \n",
       "4           4     1001820  mengejar  2801   \n",
       "\n",
       "                                             kalimat  freq  \n",
       "0  [berencana, pulang, amerika, serikat, volume, ...     1  \n",
       "1  [berencana, pulang, amerika, serikat, volume, ...     1  \n",
       "2  [mekanisme, memicu, produksi, nasional, ketida...     1  \n",
       "3  [mekanisme, memicu, produksi, nasional, ketida...     1  \n",
       "4  [ganti, kaum, melayu, melepaskan, ketuanan, me...     1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_double_annotator_disagree.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to pick collocation range of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "collocs = []\n",
    "for row in cleaned_double_annotator_disagree.values:\n",
    "    kata = row[2]\n",
    "    kalimat = row[4]\n",
    "    try:\n",
    "        target_index = kalimat.index(kata)\n",
    "    except ValueError:\n",
    "        colloc = ['','','','']\n",
    "        collocs.append(colloc)\n",
    "        continue\n",
    "    panjang_kalimat = len(kalimat)\n",
    "    if target_index == 1:\n",
    "        if panjang_kalimat - target_index > 2:\n",
    "            colloc = ['',kalimat[target_index-1],kalimat[target_index+1],kalimat[target_index+2]]\n",
    "        elif panjang_kalimat - target_index == 2:\n",
    "            colloc = ['',kalimat[target_index-1],kalimat[target_index+1],'']\n",
    "        else:\n",
    "            colloc = ['',kalimat[target_index-1],'','']\n",
    "    elif target_index == 0:\n",
    "        if panjang_kalimat - target_index > 2:\n",
    "            colloc = ['','',kalimat[target_index+1],kalimat[target_index+2]]\n",
    "        elif panjang_kalimat - target_index == 2:\n",
    "            colloc = ['','',kalimat[target_index+1],'']\n",
    "    else:\n",
    "        if panjang_kalimat - target_index > 2:\n",
    "            colloc = [kalimat[target_index-2],kalimat[target_index-1],kalimat[target_index+1],kalimat[target_index+2]]\n",
    "        elif panjang_kalimat - target_index == 2:\n",
    "            colloc = [kalimat[target_index-2],kalimat[target_index-1],kalimat[target_index+1],'']\n",
    "        else:\n",
    "            colloc = [kalimat[target_index-2],kalimat[target_index-1],'','']\n",
    "    collocs.append(colloc)\n",
    "# collocs = np.array(collocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_double_annotator_disagree['colloc'] = collocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kalimat_id</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "      <th>freq</th>\n",
       "      <th>colloc</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001238</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[berencana, pulang, amerika, serikat, volume, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[vermouth, berjanji, sherry, ]</td>\n",
       "      <td>[vermouth, berjanji, sherry, , berencana, pula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1001238</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>[berencana, pulang, amerika, serikat, volume, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[vermouth, berjanji, sherry, ]</td>\n",
       "      <td>[vermouth, berjanji, sherry, , berencana, pula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1001448</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[mekanisme, memicu, produksi, nasional, ketida...</td>\n",
       "      <td>1</td>\n",
       "      <td>[muncul, film, kewajiban, mutunya]</td>\n",
       "      <td>[muncul, film, kewajiban, mutunya, mekanisme, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1001448</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>[mekanisme, memicu, produksi, nasional, ketida...</td>\n",
       "      <td>1</td>\n",
       "      <td>[muncul, film, kewajiban, mutunya]</td>\n",
       "      <td>[muncul, film, kewajiban, mutunya, mekanisme, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1001820</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[ganti, kaum, melayu, melepaskan, ketuanan, me...</td>\n",
       "      <td>1</td>\n",
       "      <td>[melayu, dibantu, ketertinggalan, ekonominya]</td>\n",
       "      <td>[melayu, dibantu, ketertinggalan, ekonominya, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  kalimat_id      kata sense  \\\n",
       "0           0     1001238  mengejar  2801   \n",
       "1           1     1001238  mengejar  2802   \n",
       "2           2     1001448  mengejar  2801   \n",
       "3           3     1001448  mengejar  2802   \n",
       "4           4     1001820  mengejar  2801   \n",
       "\n",
       "                                             kalimat  freq  \\\n",
       "0  [berencana, pulang, amerika, serikat, volume, ...     1   \n",
       "1  [berencana, pulang, amerika, serikat, volume, ...     1   \n",
       "2  [mekanisme, memicu, produksi, nasional, ketida...     1   \n",
       "3  [mekanisme, memicu, produksi, nasional, ketida...     1   \n",
       "4  [ganti, kaum, melayu, melepaskan, ketuanan, me...     1   \n",
       "\n",
       "                                          colloc  \\\n",
       "0                 [vermouth, berjanji, sherry, ]   \n",
       "1                 [vermouth, berjanji, sherry, ]   \n",
       "2             [muncul, film, kewajiban, mutunya]   \n",
       "3             [muncul, film, kewajiban, mutunya]   \n",
       "4  [melayu, dibantu, ketertinggalan, ekonominya]   \n",
       "\n",
       "                                            features  \n",
       "0  [vermouth, berjanji, sherry, , berencana, pula...  \n",
       "1  [vermouth, berjanji, sherry, , berencana, pula...  \n",
       "2  [muncul, film, kewajiban, mutunya, mekanisme, ...  \n",
       "3  [muncul, film, kewajiban, mutunya, mekanisme, ...  \n",
       "4  [melayu, dibantu, ketertinggalan, ekonominya, ...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_double_annotator_disagree.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Feature Vector to be fed to classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features vector construction is:\n",
    "\n",
    "[Word, Colloc1, Colloc2, Colloc3, Colloc4, sentence1, ... , sentencen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for row in cleaned_double_annotator_disagree.values:\n",
    "    cur = [row[2]]\n",
    "    cur += row[6] + row[4]\n",
    "    features.append(cur)\n",
    "cleaned_double_annotator_disagree['features'] = features\n",
    "# features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kalimat_id</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "      <th>freq</th>\n",
       "      <th>colloc</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001238</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[berencana, pulang, amerika, serikat, volume, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[vermouth, berjanji, sherry, ]</td>\n",
       "      <td>[mengejar, vermouth, berjanji, sherry, , beren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1001238</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>[berencana, pulang, amerika, serikat, volume, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[vermouth, berjanji, sherry, ]</td>\n",
       "      <td>[mengejar, vermouth, berjanji, sherry, , beren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1001448</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[mekanisme, memicu, produksi, nasional, ketida...</td>\n",
       "      <td>1</td>\n",
       "      <td>[muncul, film, kewajiban, mutunya]</td>\n",
       "      <td>[mengejar, muncul, film, kewajiban, mutunya, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1001448</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>[mekanisme, memicu, produksi, nasional, ketida...</td>\n",
       "      <td>1</td>\n",
       "      <td>[muncul, film, kewajiban, mutunya]</td>\n",
       "      <td>[mengejar, muncul, film, kewajiban, mutunya, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1001820</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2801</td>\n",
       "      <td>[ganti, kaum, melayu, melepaskan, ketuanan, me...</td>\n",
       "      <td>1</td>\n",
       "      <td>[melayu, dibantu, ketertinggalan, ekonominya]</td>\n",
       "      <td>[mengejar, melayu, dibantu, ketertinggalan, ek...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  kalimat_id      kata sense  \\\n",
       "0           0     1001238  mengejar  2801   \n",
       "1           1     1001238  mengejar  2802   \n",
       "2           2     1001448  mengejar  2801   \n",
       "3           3     1001448  mengejar  2802   \n",
       "4           4     1001820  mengejar  2801   \n",
       "\n",
       "                                             kalimat  freq  \\\n",
       "0  [berencana, pulang, amerika, serikat, volume, ...     1   \n",
       "1  [berencana, pulang, amerika, serikat, volume, ...     1   \n",
       "2  [mekanisme, memicu, produksi, nasional, ketida...     1   \n",
       "3  [mekanisme, memicu, produksi, nasional, ketida...     1   \n",
       "4  [ganti, kaum, melayu, melepaskan, ketuanan, me...     1   \n",
       "\n",
       "                                          colloc  \\\n",
       "0                 [vermouth, berjanji, sherry, ]   \n",
       "1                 [vermouth, berjanji, sherry, ]   \n",
       "2             [muncul, film, kewajiban, mutunya]   \n",
       "3             [muncul, film, kewajiban, mutunya]   \n",
       "4  [melayu, dibantu, ketertinggalan, ekonominya]   \n",
       "\n",
       "                                            features  \n",
       "0  [mengejar, vermouth, berjanji, sherry, , beren...  \n",
       "1  [mengejar, vermouth, berjanji, sherry, , beren...  \n",
       "2  [mengejar, muncul, film, kewajiban, mutunya, m...  \n",
       "3  [mengejar, muncul, film, kewajiban, mutunya, m...  \n",
       "4  [mengejar, melayu, dibantu, ketertinggalan, ek...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_double_annotator_disagree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure happened below because SKLearn MNB could not take an imperfect 2D array (that is, a 2D array in which the element has different array length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-747061d595f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleaned_double_annotator_disagree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleaned_double_annotator_disagree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sense'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \"\"\"\n\u001b[1;32m--> 585\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "X = cleaned_double_annotator_disagree['features'].values\n",
    "y = cleaned_double_annotator_disagree['sense'].values\n",
    "skl_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we will be using a custom MNB Classifier created as a result from Machine Learning Course Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNB_TextClassifier:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.prior = {}\n",
    "        self.condprob = {}\n",
    "    \n",
    "    # p(class=y | {term0=x[0], term1=x[1], ...} )\n",
    "    # please note that you dont add new data to vocabulary when predicting\n",
    "    def proba_y_given_x(self, y, x):\n",
    "        length = len(self.condprob)\n",
    "        prob_y = self.prior[y]\n",
    "        prob_x = 1\n",
    "        for i in x:\n",
    "            if(i in self.condprob.keys()):\n",
    "                prob_x *= (self.condprob[i][y])\n",
    "            else:\n",
    "                prob_x *= ((1)/(self.dict_y_term[y] + length))\n",
    "        return prob_y * prob_x\n",
    " \n",
    "        #raise NotImplementedError()\n",
    "    \n",
    "    # p(c)\n",
    "    def proba_y(self, y):\n",
    "        return self.prior[y]\n",
    "\n",
    "    # update self.prior[class] as p(class=class) \n",
    "    # update self.condprob[term][class] as p(term=term | class=class)\n",
    "    def fit(self, X, y):\n",
    "        dict_y = {i:list(y).count(i) for i in y}\n",
    "        total_y = 0\n",
    "\n",
    "        for i in dict_y:\n",
    "            total_y += dict_y[i]\n",
    "        for i in dict_y:\n",
    "            self.prior[i] = dict_y[i]/total_y\n",
    "        \n",
    "        X_Plain = list()\n",
    "        \n",
    "        for i in X:\n",
    "            for j in i:\n",
    "                X_Plain.append(j)\n",
    "\n",
    "        dict_x = {i:X_Plain.count(i) for i in X_Plain}\n",
    "        dict_x_dict_y = {i:dict() for i in dict_x}\n",
    "        dict_x_cond_y = {i:dict() for i in dict_x}\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            for j in X[i]:\n",
    "                if(i in dict_x_cond_y[j]):\n",
    "                    dict_x_cond_y[j][i] += 1\n",
    "                else:\n",
    "                    dict_x_cond_y[j][i] = 1\n",
    "        self.dict_y_term = {i:0 for i in y}\n",
    "        for i in range(len(y)):\n",
    "            self.dict_y_term[y[i]] += (len(X[i]))\n",
    "\n",
    "        dict_y_last = {i:{j:0 for j in self.dict_y_term} for i in dict_x_cond_y}\n",
    "\n",
    "        for i in dict_x_cond_y:\n",
    "            for j in range(len(y)):\n",
    "                if(j in dict_x_cond_y[i]):\n",
    "                    dict_y_last[i][y[j]] += dict_x_cond_y[i][j] \n",
    "        self.condprob = {i:{j:0 for j in self.dict_y_term} for i in dict_x_cond_y}\n",
    "        for i in dict_y_last:\n",
    "            for j in dict_y_last[i]:\n",
    "\n",
    "                self.condprob[i][j] = (dict_y_last[i][j] + 1)/(self.dict_y_term[j] + len(dict_x))\n",
    "        #print(dict_x)\n",
    "        #print(self.dict_y_term)\n",
    "        #print(dict_y_last)\n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "    def predict_single(self, x):\n",
    "        classes = [i for i in self.prior.keys()]\n",
    "        likelihood = [self.proba_y_given_x(i,x) for i in classes]\n",
    "        return classes[likelihood.index(max(likelihood))]\n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return [self.predict_single(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_clf = MNB_TextClassifier()\n",
    "cust_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
